# Project2_UnixShell_Practice
# 🐚 Unix Shell Data Exploration Practice

## 📋 Project Overview

This project showcases the use of **Unix shell commands** and pipelines to perform data exploration. The goal was to practice chaining command-line tools to efficiently process, transform, and analyze data.

---

## 🛠️ Tasks & Techniques Covered

We applied a variety of Unix shell tools to answer real analytical questions. Key tasks included:

- **Word Count Analysis**
  - Counted specific word occurrences using `grep`, `wc`, and pipelines
  - Case-insensitive and whole-word searches for text analysis (e.g., book data)

- **Top-N Sorting**
  - Used `sort` and `head` to identify top 10 contributors, frequencies, or numeric values
  - Explored patterns such as highest donations or most frequent terms

- **Data Filtering**
  - Built filtering pipelines using `grep`, `sort`, `uniq`, and `head`
  - Extracted meaningful subsets from larger datasets for targeted insights

---
